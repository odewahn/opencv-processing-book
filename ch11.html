<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <title>OpenCV Processing Book</title>

    <!-- Bootstrap core CSS -->
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css"/>
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap-theme.min.css"/>
   <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet"/>

   <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"> </script>
   <script type="text/javascript" src="theme/html/javascripts/disqus.js"> </script>

   <link rel="stylesheet" href="theme/html/stylesheets/atlas.css"/>


  </head>

  <body data-type="book">

    <div class="navbar navbar-fixed-top" role="navigation">	
      <div class="container">
        <div class="navbar-header">	
	  <img class="logo" src="theme/html/assets/logo-white.svg"/>
          <a class="title" href="#">OpenCV Processing Book</a>
        </div>

	<div id="slideout">
	    <span class="toc-control fa fa-bars"/>
	    <div id="slideout_inner">
		 <div class="input-group">
	            <input type="text" class="form-control" placeholder="Search" name="srch-term" id="srch-term"/>
	            <div class="input-group-btn">
	               <button class="btn btn-default search-button" type="submit"><span class="fa fa-search"/></button>
	            </div>
	         </div>   
	        <h2>Contents</h2>
	        <nav data-type="toc" id="idp89424"><ol><li data-type="chapter"><a href="ch01.html#idp493232">Filters: Basic Output</a></li><li data-type="chapter"><a href="ch02.html#idm1279744">Filters: Blur</a><ol>




<li data-type="sect1"><a href="ch02.html#idp550560">Blur Strength and Direction - Convolutions and Kernels</a><ol>
























<li data-type="sect2"><a href="ch02.html#idp845296">Color Images</a></li>
</ol></li>
<li data-type="sect1"><a href="ch02.html#idp546208">Parameters</a></li>
<li data-type="sect1"><a href="ch02.html#idp852656">Related Functions</a></li>
</ol></li><li data-type="chapter"><a href="ch03.html#idp858368">Filters: Brightness and Contrast</a></li><li data-type="chapter"><a href="ch04.html#idp859552">Filters: Dilate and Erode</a></li><li data-type="chapter"><a href="ch05.html#idp860064">Filters: Edge Detection</a><ol>



<li data-type="sect1"><a href="ch05.html#idp866960">Canny Edge Detection</a></li>
<li data-type="sect1"><a href="ch05.html#idp876112">Sobel Edge Detection</a><ol>




<li data-type="sect2"><a href="ch05.html#idp876528">Parameters</a></li>
</ol></li>
<li data-type="sect1"><a href="ch05.html#idp885552">Scharr Edge Detection</a></li>
</ol></li><li data-type="chapter"><a href="ch06.html#idp890352">Filters: Histogram Equalization</a></li><li data-type="chapter"><a href="ch07.html#idp897728">Filters: In Range</a><ol>








<li data-type="sect1"><a href="ch07.html#idp914176">Use with Color Images and the Hue Channel</a></li>
<li data-type="sect1"><a href="ch07.html#idp917024">Parameters</a></li>
<li data-type="sect1"><a href="ch07.html#idp919680">Related Material</a></li>
</ol></li><li data-type="chapter"><a href="ch08.html#idp905568">Filters: Region of Interest</a><ol>





<li data-type="sect1"><a href="ch08.html#idp934672">Combined with Histogram Equalization</a></li>
<li data-type="sect1"><a href="ch08.html#idp930832">Parameters</a></li>
</ol></li><li data-type="chapter"><a href="ch09.html#idp940048">Filters: Threshold</a><ol>







<li data-type="sect1"><a href="ch09.html#idp944512">Related Functions</a></li>
<li data-type="sect1"><a href="ch09.html#idp949056">Parameters</a></li>
<li data-type="sect1"><a href="ch09.html#idp951664">Code</a></li>
</ol></li><li data-type="chapter"><a href="ch10.html#idp953744">Filters: Adaptive Threshold</a><ol>


<li data-type="sect1"><a href="ch10.html#idp954608">Related Functions</a></li>
</ol></li><li data-type="chapter"><a href="ch11.html#idp958432">Tracking: Background Subtraction</a><ol>



<li data-type="sect1"><a href="ch11.html#idp960016">Video Script</a></li>
<li data-type="sect1"><a href="ch11.html#idp963344">Video Summary</a></li>
<li data-type="sect1"><a href="ch11.html#idp964720">Quiz</a></li>
<li data-type="sect1"><a href="ch11.html#idp978960">Code</a><ol>


<li data-type="sect2"><a href="ch11.html#idp976464">Important Functions</a></li>
<li data-type="sect2"><a href="ch11.html#idp985024">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="chapter"><a href="ch12.html#idp986368">Tracking: Track the Brightest Point</a><ol>





<li data-type="sect1"><a href="ch12.html#idp988592">Video Summary</a><ol>



<li data-type="sect2"><a href="ch12.html#idp990880">Luma: A More Accurate Measure of Brightness</a></li>
</ol></li>
<li data-type="sect1"><a href="ch12.html#idp1003024">Quiz</a></li>
<li data-type="sect1"><a href="ch12.html#idp1012656">Code</a><ol>


<li data-type="sect2"><a href="ch12.html#idp1018480">Important Functions</a></li>
<li data-type="sect2"><a href="ch12.html#idp1017984">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="chapter"><a href="ch13.html#idp1021872">Tracking: Finding Contours and Lines</a><ol>


<li data-type="sect1"><a href="ch13.html#idp1023712">Video Script</a></li>
<li data-type="sect1"><a href="ch13.html#idp1026320">Video Summary</a></li>
<li data-type="sect1"><a href="ch13.html#idp1027456">Quiz</a></li>
<li data-type="sect1"><a href="ch13.html#idp1028784">Code</a><ol>


<li data-type="sect2"><a href="ch13.html#idp1029760">Important Functions</a></li>
<li data-type="sect2"><a href="ch13.html#idp1035632">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="chapter"><a href="ch14.html#idp1036768">Tracking: Face Detection</a><ol>






<li data-type="sect1"><a href="ch14.html#idp1039968">Video Summary</a></li>
<li data-type="sect1"><a href="ch14.html#idp1057120">The Politics of Face Detection</a></li>
<li data-type="sect1"><a href="ch14.html#idp1058528">Quiz</a></li>
<li data-type="sect1"><a href="ch14.html#idp1080976">Code</a><ol>


<li data-type="sect2"><a href="ch14.html#idp1082032">Important Functions</a></li>
<li data-type="sect2"><a href="ch14.html#idp1086608">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="chapter"><a href="ch15.html#idp1089776">Tracking: Color Tracking in HSV Color Space</a><ol>





<li data-type="sect1"><a href="ch15.html#idp1093280">Video Summary</a></li>
<li data-type="sect1"><a href="ch15.html#idp1105888">Quiz</a></li>
<li data-type="sect1"><a href="ch15.html#idp1109392">Code</a><ol>



<li data-type="sect2"><a href="ch15.html#idp1111296">Important Functions</a></li>
<li data-type="sect2"><a href="ch15.html#idp1117136">Browse the Code</a></li>
</ol></li>
</ol></li></ol></nav>
	    </div>
	</div>
      </div>
    </div>


    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <section data-type="chapter" data-pdf-bookmark="Chapter 11. Tracking: Background Subtraction" id="idp958432">
<h1>Tracking: Background Subtraction</h1>

<p><em>When processing video, we frequently want to separate people and objects that move (the foreground) from the fixed environment (the background). Separating foreground from  background is an important technique that enables many applications such as motion detection and object and person tracking. Here we learn how background subtraction can separate the foreground from the background in a way that is robust to changes in light and shifts in long-still objects.</em></p>
<section data-type="sect1" data-pdf-bookmark="Video Script" id="idp960016">
<h1>Video Script</h1>

<p>[demo of final version?]
* Separating an image into foreground and background components </p>
<p>[diff video]</p>
<ul>
<li>A naive way to </li>
</ul>
</section>
<section data-type="sect1" data-pdf-bookmark="Video Summary" id="idp963344">
<h1>Video Summary</h1>

<ul>
<li>It’s hard to figure out which part of the image is the background</li>
<li>Naive version: save the background and then do a diff with each frame. </li>
<li>Need a clean background frame for reference. What happens if objects are permanently removed or shifted? What about as the light changes?</li>
<li>More sophisticated models of the background: adapt as the background changes.</li>
<li>We’ll use a background subtraction technique built-in to OpenCV that does just that.</li>
<li>The original paper: <a href="http://www.ee.surrey.ac.uk/CVSSP/Publications/papers/KaewTraKulPong-AVBS01.pdf">An Improved Adaptive Background Mixture Model for Real- time Tracking with Shadow Detection</a>.</li>
<li>Lessen the effect of small repetitive motions like moving trees and bushes.</li>
<li>Adaptive Gaussian Mixture Model - explain each pixel in the scene as the sum of a series of colors that fall off in a Gaussian distribution. Background colors are ones which stay longer and more static. Moving objects change frequently because of the changing angles of their surfaces that reflect the light.</li>
<li>When using background subtraction, we can choose how many frames affect our calculation of the background and how much effect each new frame should have.</li>
<li>Background subtraction produces a binary image: white where frame is changing, black elsewhere</li>
<li>We can then shape up what we find with dilate and erode to close holes in each blob</li>
<li>And run contour finding on them so we have it as data.</li>
<li>A next step would be to group together these clusters of contours and to add “temporal coherence”: to know how blobs move from frame to frame.</li>
</ul>
</section>
<section data-type="sect1" data-pdf-bookmark="Quiz" id="idp964720">
<h1>Quiz</h1>

<p>Q: In which of the following conditions is background subtraction superior to a simple diff: A) When you have very few frames to work with. B) When light conditions are changing. C) When you need to record the change in color within the image. D) All of the above.</p>
<p>Answer: B</p>
<p>Q: Which of these factors will not affect the performance of background subtraction: A) The amount of frames of history taken into account. B) The size of the input image. C) The number of moving objects in the scene. D) All affect it.</p>
<p>Answer: C</p>
<p>Q: True or false: background subtraction gives you the location of a particular object as it crosses the scene?</p>
<p>Answer: False </p>
</section>
<section data-type="sect1" data-pdf-bookmark="Code" id="idp978960">
<h1>Code</h1>

<section data-type="sect2" data-pdf-bookmark="Important Functions" id="idp976464">
<h2>Important Functions</h2>

<ul>
<li><code>opencv.startBackgroundSubtraction()</code> - Setup the background subtraction process.</li>
<li><code>opencv.updateBackground()</code> - Update the background based on the current image.</li>
<li><code>opencv.dilate()</code> - Thicken the shapes in the current image.</li>
<li><code>opencv.erode()</code> - Thin the shapes in the current image. When used in combination with <code>opencv.dilate()</code> this will close holes.</li>
<li><code>opencv.findContours()</code> - Find contours based on the current gray image.</li>
</ul>
</section>
<section data-type="sect2" data-pdf-bookmark="Browse the Code" id="idp985024">
<h2>Browse the Code</h2>

</section>
</section>
</section>
        </div>
      </div>
    </div>
  
    <div class="container">
	<div class="row">
	  <div class="pagination">
	      <ul>
	        <li class="prev"><span class="fa fa-chevron-left"/> <a href="ch10.html">Previous</a></li>
	        <li class="next"><a href="ch12.html">Next</a> <span class="fa fa-chevron-right"/></li>
	      </ul>
	  </div>       
	</div>
    </div>

    <div class="container">
       <div class="row">
          <div class="col-md-12 disqus">
	     <div id="disqus_thread"/>
	   </div>
       </div>
    </div>
 
    <div class="footer">
      <footer>
        <p>© O'Reilly Media, 2014</p>
      </footer>
    </div>

  </body>

</html>
