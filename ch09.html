<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <title>Getting Started with Computer Vision with OpenCV and Processing</title>

    <!-- Bootstrap core CSS -->
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css"/>
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap-theme.min.css"/>
   <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet"/>

   <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"> </script>
   <script type="text/javascript" src="theme/html/javascripts/disqus.js"> </script>

   <link rel="stylesheet" href="theme/html/stylesheets/atlas.css"/>


  </head>

  <body data-type="book">
	
   <a href="https://github.com/atduskgreg/opencv-processing-book"><img style="z-index: 999999999; position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Discuss on GitHub"/></a>


    <div class="navbar navbar-fixed-top" role="navigation">	
      <div class="container">
        <div class="navbar-header">	
	  <img class="logo" src="theme/html/assets/logo-white.svg"/>
          <a class="title" href="/">Getting Started with Computer Vision with OpenCV and Processing</a>
        </div>

	<div id="slideout">
	    <span class="toc-control fa fa-bars"/>
	    <div id="slideout_inner">
	        <h2>Table of Contents</h2>
	        <nav data-type="toc" id="idp87552"><ol><li data-type="part"><a href="part01.html#idp18592">World of Filters</a></li><li data-type="chapter"><a href="ch01.html#idm531680">Basic Output</a></li><li data-type="chapter"><a href="ch02.html#idm1705552">Blur</a><ol>




<li data-type="sect1"><a href="ch02.html#idp87136">Blur Strength and Direction - Convolutions and Kernels</a><ol>
























<li data-type="sect2"><a href="ch02.html#idp379680">Color Images</a></li>
</ol></li>
<li data-type="sect1"><a href="ch02.html#idp83664">Parameters</a></li>
<li data-type="sect1"><a href="ch02.html#idp388352">Related Functions</a></li>
</ol></li><li data-type="chapter"><a href="ch03.html#idp393008">Dilate and Erode</a></li><li data-type="chapter"><a href="ch04.html#idp398112">Edge Detection</a><ol>



<li data-type="sect1"><a href="ch04.html#idp407824">Canny Edge Detection</a></li>
<li data-type="sect1"><a href="ch04.html#idp406880">Sobel Edge Detection</a><ol>




<li data-type="sect2"><a href="ch04.html#idp403024">Parameters</a></li>
</ol></li>
<li data-type="sect1"><a href="ch04.html#idp418784">Scharr Edge Detection</a></li>
</ol></li><li data-type="chapter"><a href="ch05.html#idp423248">Histogram Equalization</a></li><li data-type="chapter"><a href="ch06.html#idp423872">In Range</a><ol>








<li data-type="sect1"><a href="ch06.html#idp447424">Use with Color Images and the Hue Channel</a></li>
<li data-type="sect1"><a href="ch06.html#idp448768">Parameters</a></li>
<li data-type="sect1"><a href="ch06.html#idp452752">Related Material</a></li>
</ol></li><li data-type="chapter"><a href="ch07.html#idp436880">Region of Interest</a><ol>





<li data-type="sect1"><a href="ch07.html#idp467808">Combined with Histogram Equalization</a></li>
<li data-type="sect1"><a href="ch07.html#idp468064">Parameters</a></li>
</ol></li><li data-type="chapter"><a href="ch08.html#idp473584">Threshold</a><ol>







<li data-type="sect1"><a href="ch08.html#idp477632">Related Functions</a></li>
<li data-type="sect1"><a href="ch08.html#idp482176">Parameters</a></li>
<li data-type="sect1"><a href="ch08.html#idp484880">Code</a></li>
</ol></li><li data-type="chapter"><a href="ch09.html#idp486832">Track the Brightest Point</a><ol>





<li data-type="sect1"><a href="ch09.html#idp489296">Video Summary</a><ol>



<li data-type="sect2"><a href="ch09.html#idp501392">Luma: A More Accurate Measure of Brightness</a></li>
</ol></li>
<li data-type="sect1"><a href="ch09.html#idp503840">Quiz</a></li>
<li data-type="sect1"><a href="ch09.html#idp515664">Code</a><ol>


<li data-type="sect2"><a href="ch09.html#idp514016">Important Functions</a></li>
<li data-type="sect2"><a href="ch09.html#idp519008">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="part"><a href="part02.html#idp522752">Track all the Things</a></li><li data-type="chapter"><a href="ch10.html#idp524864">Face Detection</a><ol>






<li data-type="sect1"><a href="ch10.html#idp527872">Video Summary</a></li>
<li data-type="sect1"><a href="ch10.html#idp545088">The Politics of Face Detection</a></li>
<li data-type="sect1"><a href="ch10.html#idp546496">Quiz</a></li>
<li data-type="sect1"><a href="ch10.html#idp556320">Code</a><ol>


<li data-type="sect2"><a href="ch10.html#idp569872">Important Functions</a></li>
<li data-type="sect2"><a href="ch10.html#idp571648">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="part"><a href="part03.html#idp577632">Projects</a></li><li data-type="chapter"><a href="ch11.html#idp579120">Test Case 1: Film Scanner Frame Extractor</a><ol>


<li data-type="sect1"><a href="ch11.html#idp579904">Part 1: Understanding the Problem</a><ol>


<li data-type="sect2"><a href="ch11.html#idp581488">Kinograph: DIY Film Scanner</a></li>
<li data-type="sect2"><a href="ch11.html#idp586544">The Problem: Rotation and Overscan</a></li>
<li data-type="sect2"><a href="ch11.html#idp588496">How to Think about the Problem</a></li>
</ol></li>
</ol></li></ol></nav>
	    </div>
	</div>
      </div>
    </div>


    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <section data-type="chapter" data-pdf-bookmark="Chapter 9. Track the Brightest Point" id="idp486832">
<h1>Track the Brightest Point</h1>

<p><em>Probably the single simplest way to track an object with OpenCV is based on brightness. Brightness tracking is highly sensitive to lighting conditions and other changes in the scene, but it can work effectively in situations where you have a lot of control over the environment. In this section, we’ll use OpenCV’s <code>max()</code> function to track the brightest point in an image. We’ll also see how a variation of brightness tracking, applied to the individual color channels of an image, can be used for a crude form of color tracking.</em></p>
<iframe src="http://player.vimeo.com/video/69813654" width="500" height="281" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""> </iframe>

<section data-type="sect1" data-pdf-bookmark="Video Summary" id="idp489296">
<h1>Video Summary</h1>

<ul>
<li>Brightness tracking is one of the simplest ways to track an object.</li>
<li>It’s very fragile (affected by changing lighting conditions) so if you want to use it you’ll need to control the environment</li>
<li>By default, our OpenCV object works off of a grayscale version of the input image.</li>
<li>Grayscale pixel values range from 0 (for black) to 255 (for white).</li>
<li>The pixel with the maximum value in this image will be the brightest point. (See the note about Luma as a measure of brightness below.)</li>
<li>If multiple pixels share the same maximum value (usually all white or all black if the image itself is all black), then the top-leftmost pixel will be selected.</li>
<li>We can make this dynamic by processing each new frame of a Capture object.</li>
<li>This technique works for any grayscale image.</li>
<li>OpenCV gives us the red, blue, and green channels of our image as individual grayscale images.</li>
<li>Finding the max of these individual channels will find the reddest, greenest, and bluest channel respectively.</li>
<li>This form of color tracking is very crude because of the limitations of RGB color space</li>
<li>See the Color Tracking in HSV Color Space for a more robust technique for tracking color. </li>
</ul>
<section data-type="sect2" data-pdf-bookmark="Luma: A More Accurate Measure of Brightness" id="idp501392">
<h2>Luma: A More Accurate Measure of Brightness</h2>

<p><a href="http://en.wikipedia.org/wiki/Luma_%28video%29">Luma</a> is a representation of the brightness of a pixel that matches human perception more accurately than its gray value, which is a simple average of the reg, green, and blue components. Luma can be calculated as an unequal combination of the red, green and blue components of the pixel according to the following formula: 0.2126*R + 0.7152*G + 0.0722*B. To use Luma for brightness tracking with our OpenCV image, you could iterate through the image and calculate the Luma value for each pixel, which would be slow. Or, you could use OpenCV’s <code><a href="http://docs.opencv.org/java/org/opencv/imgproc/Imgproc.html#cvtColor">Imgproc.cvtColor()</a></code> function in concert with <code>opencv.getBufferColor()</code> to convert the image to the <a href="https://en.wikipedia.org/wiki/Lab_color_space">LAB color space</a>, which includes Luma as one of its three channels.</p>
<p>This image demonstrates the comparison. The difference can be subtle. Click through to the larger size to make sure you see it. Look carefully at the right side of the image around the flashlight.</p>
<p><a href="http://www.flickr.com/photos/unavoidablegrain/9228785034/" title="Gray vs Luma by atduskgreg, on Flickr"><img src="http://farm3.staticflickr.com/2829/9228785034_39c665d9e9.jpg" width="500" height="358" alt="Gray vs Luma"/></a></p>
<p>The code for this example (showing how to access the Luma channel) is here: <a href="https://github.com/atduskgreg/OpenCVPro/blob/library_rename/examples/LumaVsGray/LumaVsGray.pde">LumaVsGray.pde</a>.</p>
<p>In practice, the grayscale average of RGB is usually used due to its convenience.</p>
</section>
</section>
<section data-type="sect1" data-pdf-bookmark="Quiz" id="idp503840">
<h1>Quiz</h1>

<p>Q: What qualities of our input image could cause problems with brightness tracking: A) The presence of many glowing objects. B) Moving shadows cast by passersby. C) The auto-exposure on our camera triggering. D) All of the above.</p>
<p>Answer: D, all of the above.</p>
<p>Q: Which are easier to track with this version of color tracking: bright red or dark red objects?</p>
<p>Answer: Light red. Dark red objects will converge with the shadows in the scene where R, G, and B components are all near 0.</p>
<p>Q: What are some techniques we could use to prevent the brightest point from jumping around so much when tracking an object with this method?</p>
<p>Answer: 1) Lerp the x- and y-components of the brightest point between sequential frames. 2) Blur the image before finding the max to smooth over small differences between values. 3) Filter out large jumps in the position of the point, as they’re probably due to glitches rather than the continuous motion of the tracked object.</p>
</section>
<section data-type="sect1" data-pdf-bookmark="Code" id="idp515664">
<h1>Code</h1>

<section data-type="sect2" data-pdf-bookmark="Important Functions" id="idp514016">
<h2>Important Functions</h2>

<ul>
<li><code>opencv.max()</code> - Find the brightest point in the current gray image.</li>
<li><code>opencv.setBufferGray()</code> - Set the current gray image to another channel.</li>
<li><code>opencv.getBufferG()</code> - Get the green channel of the current image. Useful for passing to <code>opencv.setBufferGray()</code>.</li>
</ul>
</section>
<section data-type="sect2" data-pdf-bookmark="Browse the Code" id="idp519008">
<h2>Browse the Code</h2>

<ol>
<li>capture image and load it into opencv</li>
<li>find and draw the max point</li>
<li>Switch to Capture instead of a still image</li>
<li>Use the green channel to track a green object</li>
</ol>
</section>
</section>
</section>
        </div>
      </div>
    </div>
  
    <div class="container">
	<div class="row">
	  <div class="pagination">
	      <ul>
	        <li class="prev"><span class="fa fa-chevron-left"/> <a href="ch08.html">Previous</a></li>
	        <li class="next"><a href="part02.html">Next</a> <span class="fa fa-chevron-right"/></li>
	      </ul>
	  </div>       
	</div>
    </div>

    <div class="container">
       <div class="row">
          <div class="col-md-12 disqus">
	     <div id="disqus_thread"/>
	   </div>
       </div>
    </div>
 
    <div class="footer">
      <footer>
        <p>© O'Reilly Media, 2014</p>
      </footer>
    </div>

  </body>

</html>
