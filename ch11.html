<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <title>Getting Started with Computer Vision with OpenCV and Processing</title>

    <!-- Bootstrap core CSS -->
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css"/>
   <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap-theme.min.css"/>
   <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet"/>

   <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"> </script>
   <script type="text/javascript" src="theme/html/javascripts/disqus.js"> </script>

   <link rel="stylesheet" href="theme/html/stylesheets/atlas.css"/>


  </head>

  <body data-type="book">
	
   <a href="https://github.com/atduskgreg/opencv-processing-book"><img style="z-index: 999999999; position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Discuss on GitHub"/></a>


    <div class="navbar navbar-fixed-top" role="navigation">	
      <div class="container">
        <div class="navbar-header">	
	  <img class="logo" src="theme/html/assets/logo-white.svg"/>
          <a class="title" href="/opencv-processing-book/">Getting Started with Computer Vision with OpenCV and Processing</a>
        </div>

	<div id="slideout">
	    <span class="toc-control fa fa-bars"/>
	    <div id="slideout_inner">
	        <h2>Table of Contents</h2>
	        <nav data-type="toc" id="idp81104"><ol><li data-type="part"><a href="part01.html#idp18944">World of Filters</a></li><li data-type="chapter"><a href="ch01.html#idm911248">Basic Output</a></li><li data-type="chapter"><a href="ch02.html#idm1704144">Blur</a><ol>




<li data-type="sect1"><a href="ch02.html#idp87488">Blur Strength and Direction - Convolutions and Kernels</a><ol>
























<li data-type="sect2"><a href="ch02.html#idp380032">Color Images</a></li>
</ol></li>
<li data-type="sect1"><a href="ch02.html#idp83408">Parameters</a></li>
<li data-type="sect1"><a href="ch02.html#idp388960">Related Functions</a></li>
</ol></li><li data-type="chapter"><a href="ch03.html#idp393456">Dilate and Erode</a></li><li data-type="chapter"><a href="ch04.html#idp394032">Edge Detection</a><ol>



<li data-type="sect1"><a href="ch04.html#idp412064">Canny Edge Detection</a></li>
<li data-type="sect1"><a href="ch04.html#idp410800">Sobel Edge Detection</a><ol>




<li data-type="sect2"><a href="ch04.html#idp412880">Parameters</a></li>
</ol></li>
<li data-type="sect1"><a href="ch04.html#idp419072">Scharr Edge Detection</a></li>
</ol></li><li data-type="chapter"><a href="ch05.html#idp423776">Histogram Equalization</a></li><li data-type="chapter"><a href="ch06.html#idp424352">In Range</a><ol>








<li data-type="sect1"><a href="ch06.html#idp447744">Use with Color Images and the Hue Channel</a></li>
<li data-type="sect1"><a href="ch06.html#idp450832">Parameters</a></li>
<li data-type="sect1"><a href="ch06.html#idp453280">Related Material</a></li>
</ol></li><li data-type="chapter"><a href="ch07.html#idp432016">Region of Interest</a><ol>





<li data-type="sect1"><a href="ch07.html#idp468112">Combined with Histogram Equalization</a></li>
<li data-type="sect1"><a href="ch07.html#idp472720">Parameters</a></li>
</ol></li><li data-type="chapter"><a href="ch08.html#idp473856">Threshold</a><ol>







<li data-type="sect1"><a href="ch08.html#idp478048">Related Functions</a></li>
<li data-type="sect1"><a href="ch08.html#idp482592">Parameters</a></li>
<li data-type="sect1"><a href="ch08.html#idp485280">Code</a></li>
</ol></li><li data-type="chapter"><a href="ch09.html#idp487104">Track the Brightest Point</a><ol>





<li data-type="sect1"><a href="ch09.html#idp489168">Video Summary</a><ol>



<li data-type="sect2"><a href="ch09.html#idp491536">Luma: A More Accurate Measure of Brightness</a></li>
</ol></li>
<li data-type="sect1"><a href="ch09.html#idp504240">Quiz</a></li>
<li data-type="sect1"><a href="ch09.html#idp515648">Code</a><ol>


<li data-type="sect2"><a href="ch09.html#idp514000">Important Functions</a></li>
<li data-type="sect2"><a href="ch09.html#idp518032">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="part"><a href="part02.html#idp523088">Track all the Things</a></li><li data-type="chapter"><a href="ch10.html#idp525136">Face Detection</a><ol>






<li data-type="sect1"><a href="ch10.html#idp528208">Video Summary</a></li>
<li data-type="sect1"><a href="ch10.html#idp545616">The Politics of Face Detection</a></li>
<li data-type="sect1"><a href="ch10.html#idp547024">Quiz</a></li>
<li data-type="sect1"><a href="ch10.html#idp569360">Code</a><ol>


<li data-type="sect2"><a href="ch10.html#idp570304">Important Functions</a></li>
<li data-type="sect2"><a href="ch10.html#idp575072">Browse the Code</a></li>
</ol></li>
</ol></li><li data-type="part"><a href="part03.html#idp578240">Projects</a></li><li data-type="chapter"><a href="ch11.html#idp579648">Test Case 1: Film Scanner Frame Extractor</a><ol>


<li data-type="sect1"><a href="ch11.html#idp580464">Part 1: Understanding the Problem</a><ol>


<li data-type="sect2"><a href="ch11.html#idp581952">Kinograph: DIY Film Scanner</a></li>
<li data-type="sect2"><a href="ch11.html#idp590992">The Problem: Rotation and Overscan</a></li>
<li data-type="sect2"><a href="ch11.html#idp597120">How to Think about the Problem</a></li>
</ol></li>
</ol></li></ol></nav>
	    </div>
	</div>
      </div>
    </div>


    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <section data-type="chapter" data-pdf-bookmark="Chapter 11. Test Case 1: Film Scanner Frame Extractor" id="idp579648">
<h1>Test Case 1: Film Scanner Frame Extractor</h1>

<section data-type="sect1" data-pdf-bookmark="Part 1: Understanding the Problem" id="idp580464">
<h1>Part 1: Understanding the Problem</h1>

<section data-type="sect2" data-pdf-bookmark="Kinograph: DIY Film Scanner" id="idp581952">
<h2>Kinograph: DIY Film Scanner</h2>

<p><a href="http://mepler.com/Kinograph">Kinograph</a> is an open source DIY film scanner currently under development by Matt Epler, an archivist and hacker. Film scanners digitize analogue movies by photographing each frame of film one at a time. Existing models cost upwards of $100,000. Much of the cost arises from the need for precision hardware to place each frame of film in exactly the same location every time.</p>
<p>Using computer vision, we can reduce the need for this precision. Instead of having to get each film frame into exactly the same spot, we can write a program that finds each frame within an image and extracts it.</p>
<p>Kinograph’s software uses exactly these techniques. The result is that Kinograph’s hardware costs less than $1,000 and will be available to many more archivists enabling the preservation of many films that would otherwise be lost.</p>
<p>In this test case, we’ll approach the problem of detecting and extracting frames from images of a film captured with Kinograph. We’ll see how OpenCV’s image filtering, edge detection, contour detection, and polygon approximation functions can be used to align and extract individual frames from the scanned film.</p>
</section>
<section data-type="sect2" data-pdf-bookmark="The Problem: Rotation and Overscan" id="idp590992">
<h2>The Problem: Rotation and Overscan</h2>

<p><a href="http://www.flickr.com/photos/unavoidablegrain/9142159361/" title="Kinograph source image by atduskgreg, on Flickr"><img src="http://farm3.staticflickr.com/2887/9142159361_78755f06e4.jpg" width="333" height="500" alt="Kinograph source image"/></a></p>
<p>Raw Kinograph scans (as seen above) present two main challenges for frame extraction: rotation and overscan.</p>
<p>As the film moves through the machine it does not always stay perfectly parallel to the camera that captures the scans. In order to correct this problem, we’ll have to figure out the orientation of the frame of film within each scan so we can rotate the image to make the frame parallel with its edges.</p>
<p>Each Kinograph scan also captures more than just the current frame. As you can see in the image above, half of the previous and next frames are also visible. This excess area is called “overscan” in the digitization biz. It’s necessary for other processes like stitching the audio track together, but it’s exactly what we have to eliminate to produce a video file that looks like the original movie. In order to extract each frame, we’ll have to find its borders within the larger scan.</p>
</section>
<section data-type="sect2" data-pdf-bookmark="How to Think about the Problem" id="idp597120">
<h2>How to Think about the Problem</h2>

<p>So, how can we go about detecting the rotation and frame boundary of each scanned frame? Let’s look critically at our example scan above. What parts of this image might help us extract the information we need?</p>
<p>Well, first of all, we know that we’ll be processing multiple frames with different content within each frame. This is a moving picture, after all. So, we need to look for parts of the image that will stay consistent even as the content of the frame changes.</p>
<p>Secondly, we need parts of the image that stick out sharply from their surroundings. Unlike the human vision system, computer vision techniques are highly sensitive to subtle variations in the image. Uneven exposure, image noise, subtle gradations of brightness -- they can all make image features that seem obvious to the eye dissolve into a mixed-up jumble of pixels.</p>
<p>And, finally, we need to pick parts of the image that will actually help us find the orientation and location of the image. That means straight lines and other geometric forms that correspond to the edges of the frame and the direction of the strip of film within the scan.</p>
<section data-type="sect3" data-pdf-bookmark="Quiz" id="idp596112">
<h3>Quiz</h3>

<p>Click on two parts of the image that seem promising for detecting the orientation and location of the frame. Remember, you’re looking for parts of the image that are:</p>
<ul>
<li>Consistent even as the content of the frame changes</li>
<li>Stark enough to be resistant to variations in image quality</li>
<li>Useful in detecting the orientation and location of the film frame.</li>
</ul>
<p><em>ANSWER: frame separators, sprocket holes, frame edges</em></p>
</section>
<section data-type="sect3" data-pdf-bookmark="Answer" id="idp601872">
<h3>Answer</h3>

<p>The three parts of the image that best fit our criteria are:</p>
<ul>
<li>The horizontal frame separators</li>
<li>The frame’s vertical edges</li>
<li>The sprocket holes</li>
</ul>
<p><em>CLOSE-UP IMAGE OF FRAME SEPARATOR</em></p>
<p>As big black horizontal bars, the frame separators are maybe the starkest portion of the image. Their edges make-up straight horizontal lines, so finding them would tell us the orientation of the frame with the scan. And they border the frame itself on top and bottom, giving us half of what we need to find the frame’s location. However, the frame separators have a downside too: what happens when the frame goes completely black? Fade outs, credit sequences, and title cards are all common situations in which black areas of the frame would bleed into the frame borders, screwing up our detection.</p>
<p><em>CLOSE-UP IMAGE OF FRAME EDGE</em></p>
<p>The frame’s vertical edges aren’t as stark as the separators, but they do contrast nicely with the neighboring translucent area of the film. As straight lines, they also provide solid information about the orientation of the scan. And, as edges of the frame, they give us its left and right bounds. In fact, in combination with the vertical information from the frame separators (or any other source), the frame separators would give us enough to find the complete frame position.</p>
<p><em>CLOSE-UP IMAGE OF SPROCKET HOLE</em></p>
<p>The last part of the image that seems promising is the sprocket holes. They are geometric in shape and certain of them correspond to the top and bottom of the frame. Compared to the frame separators and edges, they’re much lower contrast. On the other hand, they’re located on a part of the film that won’t be affected by changes within the frame. Also, the sprocket holes were designed specifically to  register each frame in the projector so we can rely on them being positioned correctly. One major downside of the sprocket holes is that there are more of them than we need. In order to use them, we’d need a way to distinguish the holes at the top and bottom of the frame from all the others that appear in each scan.</p>
</section>
</section>
</section>
</section>
        </div>
      </div>
    </div>
  
    <div class="container">
	<div class="row">
	  <div class="pagination">
	      <ul>
	        <li class="prev"><span class="fa fa-chevron-left"/> <a href="part03.html">Previous</a></li>
	        <li class="next"> <span class="fa fa-chevron-right"/></li>
	      </ul>
	  </div>       
	</div>
    </div>

    <div class="container">
       <div class="row">
          <div class="col-md-12 disqus">
	     <div id="disqus_thread"/>
	   </div>
       </div>
    </div>
 
    <div class="footer">
      <footer>
        <p>© O'Reilly Media, 2014</p>
      </footer>
    </div>

  </body>

</html>
